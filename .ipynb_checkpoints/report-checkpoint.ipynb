{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Area\n",
    "\n",
    "I chose to look at OpenStreetMap (OSM) data from the city of Guadalajara in the state of Jalisco, Mexico.  I spent some time living in Guadalajara and was curious to know about contributions made to the city's OSM database as well as how differences in language were handled.  The map area can be found on the OSM website here:\n",
    "\n",
    "http://www.openstreetmap.org/export#map=10/20.6174/-103.3271\n",
    "\n",
    "To get the data, I created a Mapzen custom extract.  It turns out these can be finicky after some time, so I've also included an alternative download via the Overpass API (the geo bounding box is slightly different):\n",
    "\n",
    "- https://s3.amazonaws.com/mapzen.odes/ex_tvaWMoe8QMguj4B6VLUnzwrfCbNc4.osm.bz2 (compressed, quicker)\n",
    "\n",
    "- http://overpass-api.de/api/map?bbox=-104.3536,20.0753,-102.3006,21.1575 (slower, more reliable)\n",
    "\n",
    "After getting the data (see `get_data.py`), I performed a quick audit of the different [elements](https://wiki.openstreetmap.org/wiki/Elements) (parent and child) in the OSM file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nd', 449143),\n",
       " ('node', 352351),\n",
       " ('tag', 183288),\n",
       " ('way', 54197),\n",
       " ('member', 1717),\n",
       " ('relation', 531),\n",
       " ('bounds', 1),\n",
       " ('osm', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from audit_fields import audit_elements\n",
    "audit_elements(\"gdl.osm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as an audit of the tag keys (i.e. the 'k' attribute of the XML tag element).  As an example, the 20 most frequent tag keys are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('highway', 149433),\n",
       " ('name', 91206),\n",
       " ('amenity', 27141),\n",
       " ('source', 24597),\n",
       " ('oneway', 23622),\n",
       " ('addr:street', 21912),\n",
       " ('operator', 21444),\n",
       " ('addr:postcode', 21063),\n",
       " ('source:date', 20289),\n",
       " ('SEP:CLAVEESC', 20085),\n",
       " ('is_in:suburb', 14061),\n",
       " ('description', 11682),\n",
       " ('power', 9084),\n",
       " ('desciption', 8430),\n",
       " ('building', 7617),\n",
       " ('surface', 5481),\n",
       " ('access', 5355),\n",
       " ('width:street', 5268),\n",
       " ('leisure', 3657),\n",
       " ('maxspeed', 3366)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from audit_fields import audit_tag_keys\n",
    "data = audit_tag_keys(\"gdl.osm\")\n",
    "data[0:20] # top 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problems in the Map\n",
    "\n",
    "The first problem that I noticed, which can be seen above, was mispelling of the `description` key as `desciption`.  I fixed the spelling for these occurrences.  To identify other problems in the map, I audited several of the above keys (see `audit_fields.py`).  As I suspected, the difference in language along with accents that are used in Spanish made things messy.  There were, however, some key-values free of error such as country and state.  For simplicity, I chose to focus on the following keys:\n",
    "\n",
    "- amenity (`amenity`)\n",
    "- street names (`addr:street`)\n",
    "- postcode (`addr:postcode`)\n",
    "- city (`addr:city`)\n",
    "- cuisine (`cuisine`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amenity\n",
    "\n",
    "I didn't know what the `SEP:CLAVEESC` key was (in top 20 above) so I did some research.  It turns out this is a unique school identifier for a national database.  For elements with this key I checked to see if there were any without a school related amenity key-value (see `audit_fields.py`).  More than a quarter of these elements didn't have a school related key-value in the amenity key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6695\n"
     ]
    }
   ],
   "source": [
    "from audit_fields import cross_ref_sep\n",
    "print cross_ref_sep(\"gdl.osm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this, I added an amenity key with the key-value `school`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Street Names\n",
    "\n",
    "There was a lot of mess in the street name fields, it is unclear if some street names left out street types inadvertently and in fact were another street name already in the data such as 'Av. Vallarta' and 'Vallarta'. It is entirely possible that some of these names without street types were different from their apparent counterparts so I chose not to make any assumptions. I did however expand any street abbreviations to the full word such as 'av' to 'Avenida', 'esq' to 'Esquina', and 'prol' to Prolongaci√≥n.  Below we can see all the street names beginning with an abbreviation for 'Avenida'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Av. del Bosque', 21),\n",
       " ('Av Constitucion', 9),\n",
       " ('Av. Vallarta', 6),\n",
       " ('Av. Del Bosque', 6),\n",
       " ('Av. Netzahualcoyotl', 3),\n",
       " ('Av. Azahares y Violetas', 3),\n",
       " ('Av.Clvn.Division del Nte 415,Jardines Alcalde', 3),\n",
       " ('Av. Central Guillermo Gonzalez Camarena', 3),\n",
       " (u'Av.Adolfo L\\xf3pez Mateos sur', 3),\n",
       " ('Av. Guadalupe', 3),\n",
       " ('Av. Chapultepec', 3),\n",
       " (u'Av. R\\xedo Nilo', 3),\n",
       " (u'Av. Federal\\xedstas', 3),\n",
       " (u'Av.Circunvalaci\\xf3n', 3),\n",
       " (u'Av. M\\xe9xico', 3),\n",
       " (u'Av. General Ram\\xf3n Corona', 3),\n",
       " ('Av. Acueducto', 3),\n",
       " ('Av. Paseo de los Emperadores', 3),\n",
       " ('Av.Tepeyac', 3),\n",
       " ('Av. Vallarta 4327', 3),\n",
       " ('Av. Francisco Javier Mina', 3)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from audit_fields import audit_tag_values\n",
    "data = audit_tag_values(\"gdl.osm\", \"addr:street\")\n",
    "av = [pair for pair in data if re.search(r'^av(\\s|\\.)', pair[0], re.IGNORECASE)]; av"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postal Codes\n",
    "\n",
    "Several postal codes in the data had trailing zeros or whitespace, and others were not valid postal codes for the state of Jalisco, Mexico. I confirmed valid postal codes via wikipedia, those that are valid begin with numbers 44 through 48 and are 5 digits long in total. Any postal codes not beginning with these numbers were left out. For those with trailing zeros or whitespace, it was assumed that these characters were mistakes and they were removed from the rest of the postal code.  The results below show postcodes not containing 5 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('58350', 3),\n",
       " ('1300', 3),\n",
       " ('445100', 3),\n",
       " ('454009', 3),\n",
       " ('7002079', 3),\n",
       " ('30983', 3),\n",
       " ('454030', 3),\n",
       " ('38901', 3)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = audit_tag_values(\"gdl.osm\", \"addr:postcode\")\n",
    "invalid = [pair for pair in data if not re.search(r'^4[4-8]\\d{3}$', pair[0])]; invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### City Names\n",
    "\n",
    "Some city names were completely out of place such as 'Morelia' which is not in the state of Jaliso.  There were also inconsistencies with spelling, accents, capitalization, and the inclusion of the state name along with the city name. For example, 'GUADALAJARA JALISCO', 'Guadalajara Jalisco', and 'Guadalajara, Jalisco'. These types of errors occurred in only a few of the main municipalities in the Guadalajara area and were corrected with a simple search and replace function. To make sure that other city names were legitimate, I scraped data from a wikipedia page containing city names in the state of Jalisco and compared them with those encountered in the OpenStreetMap file (see `scrape_cities.py`). If the city name was not in this list, it was omitted.  Below is an audit (value and number of occurrences) of the city names containing the word 'Guadalajara'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Guadalajara', 222),\n",
       " ('Guadalajara , Jal.', 6),\n",
       " ('Guadalajara, Jalisco', 6),\n",
       " ('guadalajara', 3),\n",
       " ('GUADALAJARA', 3),\n",
       " ('Guadalajara ,Jal.', 3),\n",
       " ('Terranova, Guadalajara, Jalisco', 3),\n",
       " ('Guadalajara Jalisco', 3),\n",
       " ('GUADALAJARA JALISCO', 3)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from audit_fields import audit_tag_values\n",
    "data = audit_tag_values(\"gdl.osm\", \"addr:city\")\n",
    "guad = [pair for pair in data if re.search(r'guad', pair[0], re.IGNORECASE)]\n",
    "guad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cuisine Types\n",
    "\n",
    "The cuisine attribute contained several different types of inconsistencies. Naming issues such as 'Hot_Dogs', 'hot_dogs', or 'Hot_Dogs_Gourmet', were all updated to simple derivative such as\n",
    "'hot_dogs'. There were also some problems with primary language, as we had fields with 'seafood' and 'mariscos'. Because most values were in English (also values are in English even in the Spanish translated OSM wiki), I chose to change anything redundant in Spanish to it's English counterpart. Some values had more than one cuisine type such as 'sushi,_burgers'. These were split up into a list for the 'cuisine' field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "After cleaning the problems found in the map (see `update_fields.py`), the original OSM XML data was converted to JSON (see `process_data.py`).  The JSON was then inserted to a MongoDB database (`import_mongo.py`).  Following are results from querying the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
